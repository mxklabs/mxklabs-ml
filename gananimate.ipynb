{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Round 0 predictions: 0.05384747311472893 ----------\n",
      "Mean score is 0.05384747311472893 -- training discriminator.\n",
      "Train on 1100 samples, validate on 275 samples\n",
      "1100/1100 [==============================] - 0s 304us/sample - loss: 0.2992 - binary_accuracy: 0.9091 - val_loss: 0.2095 - val_binary_accuracy: 0.9091\n",
      "---------- Round 1 predictions: 0.009539589285850525 ----------\n",
      "Mean score is 0.009539589285850525 -- training discriminator.\n",
      "Train on 1100 samples, validate on 275 samples\n",
      "1100/1100 [==============================] - 0s 54us/sample - loss: 0.2012 - binary_accuracy: 0.9091 - val_loss: 0.1829 - val_binary_accuracy: 0.9091\n",
      "---------- Round 2 predictions: -0.021792106330394745 ----------\n",
      "Mean score is -0.021792106330394745 -- training discriminator.\n",
      "Train on 1100 samples, validate on 275 samples\n",
      "1100/1100 [==============================] - 0s 57us/sample - loss: 0.1799 - binary_accuracy: 0.9091 - val_loss: 0.1751 - val_binary_accuracy: 0.9091\n",
      "---------- Round 3 predictions: -0.04387956112623215 ----------\n",
      "Mean score is -0.04387956112623215 -- training discriminator.\n",
      "Train on 1100 samples, validate on 275 samples\n",
      "1100/1100 [==============================] - 0s 50us/sample - loss: 0.1701 - binary_accuracy: 0.9091 - val_loss: 0.1775 - val_binary_accuracy: 0.9091\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import functools\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.collections import PathCollection\n",
    "\n",
    "from gan import Gan, Data\n",
    "import pltanimation as plta\n",
    "\n",
    "NUM_SAMPLES=100\n",
    "\n",
    "dm = 20   # discriminator granularity\n",
    "ds = 0.025 # discriminator square size\n",
    "tics = [(t+0.5)/dm for t in range(-dm, dm, 1)]\n",
    "tics_xy = np.array(list(itertools.product(tics, tics)))\n",
    "\n",
    "def animation_init(data, fig):    \n",
    "  ax = fig.add_subplot(1,1,1)\n",
    "  ax.set_title(\"Empty plot\")\n",
    "  #plot1 = ax.plot([], [])[0]\n",
    "  real = ax.scatter(data.real_x[:,0], data.real_x[:,1], label='real', s=10)\n",
    "  generator_out = ax.scatter([], [], label='generator', s=5)\n",
    "  box = ax.add_patch(Rectangle((0, 0), 0.5, 0.5, \n",
    "        linewidth=0, edgecolor='b', facecolor=(0.6,1.0,0.6), zorder=-1))\n",
    "    \n",
    "  boxes = []\n",
    "  \n",
    "  for x, y in tics_xy:\n",
    "    boxes.append(ax.add_patch(Rectangle((x-ds, y-ds), 2*ds, 2*ds, \n",
    "      linewidth=0, edgecolor='b', facecolor=(0.6,1.0,0.6), zorder=-1)))\n",
    "    \n",
    "  \"\"\"\n",
    "    \n",
    "    tics_xy = np.array(list(itertools.product(tics, tics)))\n",
    "    tics_pred = discriminator.predict(tics_xy)\n",
    "    dis_items = np.concatenate((tics_xy, tics_pred), axis=-1)\n",
    "    dis_items = dis_items[(dis_items[:,2] >= 0.5)]\n",
    "    for x, y, pred in dis_items:\n",
    "      plt.gca().add_patch(plt.Rectangle((x-ds, y-ds), 2*ds, 2*ds, \n",
    "        linewidth=0, edgecolor='b',facecolor=(0.6,1.0,0.6),zorder=-1))\n",
    "  \"\"\"\n",
    "    \n",
    "  ax.legend(loc='upper left')\n",
    "  ax.grid(True)\n",
    "  ax.set_xlim((-1,1))\n",
    "  ax.set_ylim((-1,1))\n",
    "  return [generator_out] + boxes\n",
    "\n",
    "def animation_callback(ani, gan_model, generator, discriminator, generator_output, discriminator_output, score):\n",
    "\n",
    "    box_updates = []\n",
    "    for x, y in tics_xy:\n",
    "      out = discriminator.predict([[x, y]])[0]\n",
    "      if (out >= 0.5):\n",
    "          box_updates.append((Rectangle.set_facecolor, (0.6,1.0,0.6)))\n",
    "      else:\n",
    "          box_updates.append((Rectangle.set_facecolor, (1,1,1))) \n",
    "\n",
    "    ani.add_frame([\n",
    "        (PathCollection.set_offsets, generator_output)        \n",
    "    ] + box_updates)\n",
    "\n",
    "def gen_data(num_samples):\n",
    "  noise = np.array([random.normalvariate(0, 0.4) for _ in range(num_samples)])\n",
    "  x1 = np.array([random.random() * 2 - 1 for _ in range(num_samples)])\n",
    "  x2 = np.array((np.power(x1*2, 3) + np.sin(x1*12 - 2)*0.7 + noise)/7)\n",
    "  y = np.full(shape=(num_samples, 1), fill_value=1)\n",
    "  x1 = x1.reshape(-1,1)\n",
    "  x2 = x2.reshape(-1,1)    \n",
    "  return np.concatenate((x1, x2), axis=-1), y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "  real_x, real_y = gen_data(NUM_SAMPLES)\n",
    "  real_x_val, real_y_val = gen_data(NUM_SAMPLES//4)\n",
    "  data = Data(real_x=real_x, real_y=real_y, real_x_val=real_x_val, real_y_val=real_y_val)\n",
    "  \n",
    "  ani = plta.PltAnimation(functools.partial(animation_init, data), figsize=(10, 10)) \n",
    "    \n",
    "  latent_shape = (5,)\n",
    "  data_shape = (2,) # data shape\n",
    "  num_samples = 40\n",
    "\n",
    "  # Get real words for training.\n",
    "  latent_space = tf.keras.layers.Input(shape=latent_shape)\n",
    "\n",
    "  # Using Leaky RELU because of tip https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/.\n",
    "\n",
    "  # Discriminator input is (n, 21, 27) output is (n, 1)\n",
    "  discriminator = tf.keras.models.Sequential(name=\"discriminator\")\n",
    "  discriminator.add(tf.keras.layers.Dense(name='dhidden1', units=50, use_bias=True,\n",
    "                                          activation=tf.keras.layers.LeakyReLU(alpha=0.3), input_shape=data_shape))\n",
    "  discriminator.add(tf.keras.layers.Dense(name='dhidden2', units=50, use_bias=True,\n",
    "                                          activation=tf.keras.layers.LeakyReLU(alpha=0.3)))\n",
    "  discriminator.add(tf.keras.layers.Dense(name='dhidden3', units=15, use_bias=True,\n",
    "                                          activation=tf.keras.layers.LeakyReLU(alpha=0.3)))\n",
    "  discriminator.add(tf.keras.layers.Dense(name='doutput', units=1, use_bias=True, activation='tanh'))\n",
    "\n",
    "  #discriminator.add(tf.keras.layers.Dense(name='dhidden1', units=50, use_bias=True, activation='tanh', input_shape=data_shape))\n",
    "  #discriminator.add(tf.keras.layers.Dense(name='dhidden2', units=50, use_bias=True, activation='tanh'))\n",
    "  #discriminator.add(tf.keras.layers.Dense(name='dhidden3', units=15, use_bias=True, activation='tanh'))\n",
    "  #discriminator.add(tf.keras.layers.Dense(name='doutput', units=1, use_bias=True, activation='linear'))\n",
    "  discriminator.compile(optimizer=tf.keras.optimizers.Adam(0.0005), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "  # Generator.\n",
    "  discriminator.trainable = False\n",
    "\n",
    "  generator = tf.keras.models.Sequential(name=\"generator\")\n",
    "  generator.add(tf.keras.layers.Dense(name='ghidden1', units=15, use_bias=True, activation='tanh', input_shape=latent_shape))\n",
    "  generator.add(tf.keras.layers.Dense(name='ghidden2', units=15, use_bias=True, activation='tanh'))\n",
    "  generator.add(tf.keras.layers.Dense(name='gout', units=2, use_bias=True, activation='linear'))\n",
    "\n",
    "  gan_model = tf.keras.models.Model(latent_space, discriminator(generator(latent_space)))\n",
    "  gan_model.compile(optimizer=tf.keras.optimizers.Adam(0.0005), loss='mse', metrics=['binary_accuracy'])\n",
    "\n",
    "  gan = Gan(gan_model, data)\n",
    "  gan.train(iterations=100, epochs_per_round=1, num_samples=1000, train_discriminator_only=True, verbose=1, callback=functools.partial(animation_callback, ani))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.as_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
